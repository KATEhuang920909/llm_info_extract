{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:02:23.748356700Z",
     "start_time": "2025-10-31T10:02:14.178404100Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据处理和格式化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "412d764d869660c9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model_name = r\"D:\\competition\\llm_info_extract\\Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:03:13.606678700Z",
     "start_time": "2025-10-31T10:03:13.291787500Z"
    }
   },
   "id": "b3e658e123bc8a23"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 数据处理函数\n",
    "def process_function(example):\n",
    "    \"\"\"处理单条样本\"\"\"\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    output_text = example[\"output\"]\n",
    "    \n",
    "    # 构建Qwen2.5的对话格式\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是一个专业的命名实体识别助手。\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\\n\\n{input_text}\"},\n",
    "        {\"role\": \"assistant\", \"content\": output_text}\n",
    "    ]\n",
    "    \n",
    "    # 使用tokenizer的应用聊天模板方法\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=False\n",
    "    )\n",
    "    \n",
    "    return {\"text\": text}\n",
    "\n",
    "# 加载示例数据\n",
    "def load_sample_data():\n",
    "    \"\"\"加载示例数据\"\"\"\n",
    "    samples = [\n",
    "        {\n",
    "            \"instruction\": \"请从给定文本中识别出所有命名实体，并按照指定的实体类型进行分类。\",\n",
    "            \"input\": \"文本：After renewing the cylinder assembly , it was tested around Brighton and Eastleigh using an LNER Dynamometer car , where good running was experienced at high costs in fuel and effort on the part of the fireman .\\n\\n可选的实体类型：organization、science、politics、location、event\",\n",
    "            \"output\": \"实体识别结果：\\n1. 实体：Brighton\\n   粗类型：location\\n   细类型：city\\n2. 实体：Eastleigh\\n   粗类型：location\\n   细类型：town\"\n",
    "        },\n",
    "        # 可以添加更多样本...\n",
    "    ]\n",
    "    return samples\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            sample = json.loads(line.strip())\n",
    "            # 构造对话格式\n",
    "            conversation = process_function(sample)\n",
    "            data.append({\"conversations\": conversation})\n",
    "    return Dataset.from_list(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-10-31T10:02:27.396968900Z"
    }
   },
   "id": "2455070cdced13ff"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_data = load_data(\"stage1/ner_finetuning_train.json\")\n",
    "dev_data = load_data(\"stage1/ner_finetuning_dev.json\")\n",
    "predict_data = load_data(\"stage1/ner_finetuning_predict.json\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-10-31T10:03:14.972028900Z"
    }
   },
   "id": "c24608347be6af82"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'conversations': {'text': '<|im_start|>system\\n你是一个专业的命名实体识别助手。<|im_end|>\\n<|im_start|>user\\n请从给定文本中识别出所有命名实体，并按照指定的实体类型进行分类。\\n\\n文本：“截至9月末，深圳现金累计投放量同比出现负数。”近日，一位接近监管部门人士对本报记者称，“\\n\\n可选的实体类型：生物、职位、科学、组织机构、学历、位置<|im_end|>\\n<|im_start|>assistant\\n实体识别结果：\\n1. 实体：记者\\n   粗类型：职位\\n   细类型：概念<|im_end|>\\n'}}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:04:29.833167500Z",
     "start_time": "2025-10-31T10:04:29.817526800Z"
    }
   },
   "id": "4128472fd54f6a94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型和tokenizer加载"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a64dd9b796b891fc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# 模型配置\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 设置padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:03:25.247341800Z",
     "start_time": "2025-10-31T10:03:25.078708700Z"
    }
   },
   "id": "64f980739eea99af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LoRA配置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "809eebda1577b05a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n"
     ]
    }
   ],
   "source": [
    "# LoRA配置\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,  # LoRA秩\n",
    "    lora_alpha=32,  # LoRA alpha参数\n",
    "    lora_dropout=0.1,  # LoRA dropout\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\", \n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],  # 针对Qwen2.5的模块\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# 应用LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:03:35.971238900Z",
     "start_time": "2025-10-31T10:03:35.562592800Z"
    }
   },
   "id": "a6834de7622b31f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练参数配置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56c48225a05a4856"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen2.5-7b-ner-lora\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    warmup_steps=100,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    "    remove_unused_columns=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:03:55.578548100Z",
     "start_time": "2025-10-31T10:03:55.562799700Z"
    }
   },
   "id": "8fa0c25542b6b24c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练脚本"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddad8cb1fa59c138"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SFTTrainer.__init__() got an unexpected keyword argument 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# 创建训练器\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m trainer = \u001B[43mSFTTrainer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtraining_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43meval_dataset\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdev_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_text_field\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtext\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2048\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpacking\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 对于指令微调，建议关闭packing\u001B[39;49;00m\n\u001B[32m     11\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# trainer = SFTTrainer(\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m#     model=model,\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m#     train_dataset=train_data,\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     23\u001B[39m \n\u001B[32m     24\u001B[39m \u001B[38;5;66;03m# 开始训练\u001B[39;00m\n\u001B[32m     25\u001B[39m trainer.train()\n",
      "\u001B[31mTypeError\u001B[39m: SFTTrainer.__init__() got an unexpected keyword argument 'tokenizer'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 创建训练器\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=2048,\n",
    "    packing=False,  # 对于指令微调，建议关闭packing\n",
    ")\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=train_data,\n",
    "#     eval_dataset=dev_data,\n",
    "#     peft_config=lora_config,\n",
    "#     dataset_text_field=\"conversations\",  # 数据集中对话字段名称\n",
    "#     max_seq_length=1024,  # 最大序列长度（根据数据调整）\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_args,\n",
    "#     packing=False,  # 不打包样本（对话数据通常不打包）\n",
    "# )\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(training_args.output_dir)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-10-31T10:09:11.297968800Z",
     "start_time": "2025-10-31T10:09:11.258240400Z"
    }
   },
   "id": "8ab720a316415609"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 推理测试代码"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a2c5fa76232c206"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inference_test(model_path, input_text):\n",
    "    \"\"\"推理测试函数\"\"\"\n",
    "    # 加载模型和tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # 构建输入\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是一个专业的命名实体识别助手。\"},\n",
    "        {\"role\": \"user\", \"content\": input_text}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # 生成\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# 测试示例\n",
    "test_input = \"\"\"请从给定文本中识别出所有命名实体，并按照指定的实体类型进行分类。\n",
    "\n",
    "文本：Apple Inc. was founded by Steve Jobs in Cupertino, California.\n",
    "\n",
    "可选的实体类型：organization、person、location\"\"\"\n",
    "\n",
    "result = inference_test(\"./qwen2.5-7b-ner-lora\", test_input)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79ab062147c8f18c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
